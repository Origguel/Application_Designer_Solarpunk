# app/utils/keyword_extractor.py

import json
from pathlib import Path
import threading

# Pas de spacy import√© au d√©but
nlp = None
nlp_ready = False
nlp_lock = threading.Lock()

TERMS_PATH = Path("data/termes_interdits.json")
if TERMS_PATH.exists():
    with TERMS_PATH.open(encoding="utf-8") as f:
        termes_interdits = set(json.load(f))
else:
    termes_interdits = set()

def _load_nlp_model():
    """Charge spaCy dans un thread."""
    global nlp, nlp_ready
    import spacy  # üëà Import spacy ici seulement
    nlp = spacy.load("fr_core_news_sm")
    with nlp_lock:
        nlp_ready = True
    print("‚úÖ Mod√®le spaCy charg√©.")

def ensure_nlp_ready():
    """Assure que le mod√®le est charg√© (sinon lance le thread)."""
    global nlp_ready

    if not nlp_ready:
        print("‚ö° Chargement du mod√®le spaCy d√©clench√©...")
        threading.Thread(target=_load_nlp_model, daemon=True).start()

def extract_keywords(text):
    """Extraction de mots-cl√©s en attendant que le mod√®le soit pr√™t."""
    ensure_nlp_ready()

    global nlp

    if not nlp_ready:
        print("‚è≥ Mod√®le spaCy pas encore pr√™t, petite attente...")
        import time
        timeout = 5  # secondes
        start = time.time()
        while not nlp_ready and (time.time() - start) < timeout:
            time.sleep(0.1)

        if not nlp_ready:
            print("‚ùó Mod√®le non charg√© apr√®s 5s, extraction annul√©e.")
            return []

    doc = nlp(text.lower())
    mots_cles = []
    for token in doc:
        mot = token.lemma_
        if (
            not token.is_stop
            and not token.is_punct
            and not token.like_num
            and len(mot) > 2
            and mot not in termes_interdits
        ):
            mots_cles.append(mot)

    return list(set(mots_cles))[:6]
